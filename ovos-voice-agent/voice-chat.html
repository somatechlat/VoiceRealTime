<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üé§ OVOS Real-Time Voice Agent</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.1);
            padding: 40px;
            max-width: 600px;
            width: 100%;
            text-align: center;
        }
        
        .title {
            font-size: 2.5em;
            margin-bottom: 10px;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: bold;
        }
        
        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
        }
        
        .status {
            padding: 15px 25px;
            border-radius: 50px;
            margin: 20px 0;
            font-weight: 600;
            font-size: 1.1em;
            transition: all 0.3s ease;
        }
        
        .status.disconnected {
            background: #fee;
            color: #c33;
            border: 2px solid #fcc;
        }
        
        .status.connecting {
            background: #fff4e6;
            color: #e67e22;
            border: 2px solid #f39c12;
        }
        
        .status.connected {
            background: #eef;
            color: #27ae60;
            border: 2px solid #2ecc71;
        }
        
        .status.listening {
            background: #e8f4fd;
            color: #3498db;
            border: 2px solid #3498db;
            animation: pulse 1.5s infinite;
        }
        
        .status.thinking {
            background: #f3e5f5;
            color: #9b59b6;
            border: 2px solid #9b59b6;
            animation: thinking 1s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }
        
        @keyframes thinking {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        
        .talk-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            font-size: 3em;
            cursor: pointer;
            margin: 20px;
            transition: all 0.3s ease;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        
        .talk-button.ready {
            background: linear-gradient(45deg, #2ecc71, #27ae60);
            color: white;
        }
        
        .talk-button.recording {
            background: linear-gradient(45deg, #e74c3c, #c0392b);
            color: white;
            animation: recordingPulse 0.8s infinite;
        }
        
        .talk-button.disabled {
            background: #bdc3c7;
            color: #7f8c8d;
            cursor: not-allowed;
        }
        
        @keyframes recordingPulse {
            0%, 100% { transform: scale(1); box-shadow: 0 0 0 0 rgba(231, 76, 60, 0.7); }
            50% { transform: scale(1.1); box-shadow: 0 0 0 20px rgba(231, 76, 60, 0); }
        }
        
        .controls button {
            background: linear-gradient(45deg, #3498db, #2980b9);
            color: white;
            border: none;
            padding: 12px 24px;
            margin: 8px;
            border-radius: 25px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        
        .controls button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.15);
        }
        
        .controls button:disabled {
            background: #bdc3c7;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        .messages {
            background: #f8f9fa;
            border-radius: 15px;
            padding: 20px;
            margin: 20px 0;
            max-height: 300px;
            overflow-y: auto;
            text-align: left;
        }
        
        .message {
            margin: 10px 0;
            padding: 12px 16px;
            border-radius: 12px;
            max-width: 80%;
            word-wrap: break-word;
        }
        
        .message.user {
            background: linear-gradient(45deg, #3498db, #2980b9);
            color: white;
            margin-left: auto;
        }
        
        .message.assistant {
            background: linear-gradient(45deg, #2ecc71, #27ae60);
            color: white;
            margin-right: auto;
        }
        
        .message.system {
            background: #ecf0f1;
            color: #34495e;
            margin: 5px auto;
            border-left: 4px solid #3498db;
            font-size: 0.9em;
            font-style: italic;
        }
        
        .audio-visualizer {
            width: 100%;
            height: 60px;
            background: #ecf0f1;
            border-radius: 10px;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }
        
        .bar {
            width: 4px;
            background: #3498db;
            margin: 0 1px;
            transition: height 0.1s ease;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1 class="title">üé§ OVOS Voice Agent</h1>
        <p class="subtitle">Real-time speech conversation with AI</p>
        
        <div id="status" class="status disconnected">‚ùå Disconnected</div>
        
        <div class="controls">
            <button id="connectBtn" onclick="connect()">üîó Connect</button>
            <button id="disconnectBtn" onclick="disconnect()" disabled>‚ùå Disconnect</button>
        </div>
        
        <button id="talkButton" class="talk-button disabled" disabled onclick="toggleRecording()">üé§</button>
        
        <div id="audioVisualizer" class="audio-visualizer" style="display: none;">
            <!-- Audio visualization bars will be generated here -->
        </div>
        
        <div id="messages" class="messages">
            <div class="message system">Welcome! Connect to start voice conversation.</div>
        </div>
        
        <div style="margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 10px; font-size: 0.9em; color: #666;">
            <strong>Instructions:</strong><br>
            1. Click "Connect" to establish WebSocket connection<br>
            2. Click üé§ to start recording your voice<br>
            3. Speak naturally to the AI assistant<br>
            4. Click üé§ again to stop and get AI response<br>
            5. Listen to AI speak back to you!
        </div>
    </div>

    <script>
        let websocket = null;
        let mediaRecorder = null;
        let recordingStream = null;
        let isRecording = false;
        let isConnected = false;
        let recordingTimeout = null;

        const talkButton = document.getElementById('talkButton');
        const statusDiv = document.getElementById('status');
        const messagesDiv = document.getElementById('messages');
        const connectBtn = document.getElementById('connectBtn');
        const disconnectBtn = document.getElementById('disconnectBtn');

        // Text-to-Speech setup
        const synth = window.speechSynthesis;
        let currentVoice = null;

        // Initialize TTS voice
        function initializeTTS() {
            const voices = synth.getVoices();
            // Prefer English voices
            currentVoice = voices.find(voice => 
                voice.lang.startsWith('en') && voice.name.includes('Enhanced')
            ) || voices.find(voice => voice.lang.startsWith('en')) || voices[0];
            
            if (currentVoice) {
                addSystemMessage(`üîä TTS Voice: ${currentVoice.name} (${currentVoice.lang})`);
            }
        }

        // Initialize voices when they're loaded
        if (synth.onvoiceschanged !== undefined) {
            synth.onvoiceschanged = initializeTTS;
        }
        setTimeout(initializeTTS, 100); // Fallback

        function updateStatus(text, className) {
            statusDiv.textContent = text;
            statusDiv.className = `status ${className}`;
        }

        function addMessage(role, content) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;
            
            const time = new Date().toLocaleTimeString();
            messageDiv.innerHTML = `
                <small style="opacity: 0.7;">${time}</small><br>
                ${content}
            `;
            
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        function addSystemMessage(text) {
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message system';
            
            const time = new Date().toLocaleTimeString();
            messageDiv.innerHTML = `
                <small>${time}</small><br>
                ${text}
            `;
            
            messagesDiv.appendChild(messageDiv);
            messagesDiv.scrollTop = messagesDiv.scrollHeight;
        }

        function speakText(text) {
            // Stop any current speech
            synth.cancel();
            
            if (!text || text.trim() === '') return;
            
            const utterance = new SpeechSynthesisUtterance(text);
            
            if (currentVoice) {
                utterance.voice = currentVoice;
            }
            
            utterance.rate = 0.9;
            utterance.pitch = 1.0;
            utterance.volume = 0.8;
            
            utterance.onstart = () => {
                addSystemMessage('üîä AI is speaking...');
                updateStatus('üîä AI Speaking', 'thinking');
            };
            
            utterance.onend = () => {
                addSystemMessage('‚úÖ AI finished speaking');
                updateStatus('‚úÖ Connected - Ready', 'connected');
            };
            
            utterance.onerror = (event) => {
                addSystemMessage(`‚ùå Speech error: ${event.error}`);
            };
            
            synth.speak(utterance);
        }

        async function connect() {
            try {
                updateStatus('üîÑ Connecting...', 'connecting');
                addSystemMessage('üîÑ Connecting to OVOS server...');
                
                websocket = new WebSocket('ws://localhost:65000/v1/realtime');
                
                websocket.onopen = function() {
                    isConnected = true;
                    updateStatus('‚úÖ Connected - Ready', 'connected');
                    addSystemMessage('‚úÖ WebSocket connected successfully');
                    
                    connectBtn.disabled = true;
                    disconnectBtn.disabled = false;
                    talkButton.disabled = false;
                    talkButton.className = 'talk-button ready';
                };
                
                websocket.onmessage = function(event) {
                    try {
                        const message = JSON.parse(event.data);
                        handleMessage(message);
                    } catch (e) {
                        console.error('Failed to parse message:', e);
                        addSystemMessage(`‚ùå Parse error: ${e.message}`);
                    }
                };
                
                websocket.onclose = function() {
                    isConnected = false;
                    updateStatus('‚ùå Disconnected', 'disconnected');
                    addSystemMessage('‚ùå WebSocket disconnected');
                    
                    connectBtn.disabled = false;
                    disconnectBtn.disabled = true;
                    talkButton.disabled = true;
                    talkButton.className = 'talk-button disabled';
                    
                    if (isRecording) {
                        stopRecording();
                    }
                };
                
                websocket.onerror = function(error) {
                    addSystemMessage('‚ùå Connection failed! Make sure OVOS server is running on port 65000');
                    console.error('WebSocket error:', error);
                    updateStatus('‚ùå Connection failed', 'disconnected');
                };
                
            } catch (error) {
                addSystemMessage(`‚ùå Failed to connect: ${error.message}`);
                updateStatus('‚ùå Connection failed', 'disconnected');
            }
        }

        function disconnect() {
            if (websocket) {
                websocket.close();
                websocket = null;
            }
        }

        function sendMessage(message) {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify(message));
            }
        }

        function handleMessage(message) {
            console.log('Received message:', message);
            addSystemMessage(`üì° Event: ${message.type}`);
            
            switch (message.type) {
                case 'session.created':
                    addSystemMessage(`üîó Session created: ${message.session.id}`);
                    // Configure session for voice chat
                    sendMessage({
                        type: 'session.update',
                        session: {
                            voice: 'alloy',
                            turn_detection: {
                                type: 'server_vad',
                                threshold: 0.5,
                                prefix_padding_ms: 300,
                                silence_duration_ms: 500
                            },
                            instructions: "You are a helpful AI assistant. Keep responses conversational and brief (1-2 sentences). Speak naturally as if having a real conversation."
                        }
                    });
                    break;
                    
                case 'session.updated':
                    addSystemMessage('‚öôÔ∏è Session configured for voice chat');
                    break;
                    
                case 'input_audio_buffer.speech_started':
                    updateStatus('üé§ Voice detected!', 'listening');
                    addSystemMessage('üé§ Voice activity detected - listening...');
                    break;
                    
                case 'input_audio_buffer.speech_stopped':
                    updateStatus('üõë Processing speech...', 'thinking');
                    addSystemMessage('üõë Voice stopped - processing...');
                    break;
                    
                case 'input_audio_buffer.committed':
                    addSystemMessage('‚úÖ Audio committed - transcribing...');
                    break;
                    
                case 'conversation.item.created':
                    if (message.item && message.item.role === 'user') {
                        const transcript = message.item.content[0]?.transcript || 'Voice input';
                        addMessage('user', transcript);
                        addSystemMessage(`üë§ You said: "${transcript}"`);
                    }
                    break;
                    
                case 'response.created':
                    addSystemMessage('üß† AI is generating response...');
                    updateStatus('üß† AI thinking...', 'thinking');
                    break;
                    
                case 'response.output_item.added':
                    if (message.item && message.item.content && message.item.content[0]) {
                        const aiText = message.item.content[0].transcript;
                        if (aiText) {
                            addMessage('assistant', aiText);
                            addSystemMessage(`ü§ñ AI response: "${aiText}"`);
                            
                            // SPEAK THE RESPONSE!
                            setTimeout(() => {
                                speakText(aiText);
                            }, 500);
                        }
                    }
                    break;
                    
                case 'response.audio_transcript.delta':
                    if (message.delta) {
                        addSystemMessage(`üìù AI streaming: "${message.delta}"`);
                    }
                    break;
                    
                case 'response.audio.delta':
                    addSystemMessage('üîä Receiving audio data...');
                    break;
                    
                case 'response.audio.done':
                    addSystemMessage('‚úÖ Audio generation complete');
                    break;
                    
                case 'response.done':
                    updateStatus('‚úÖ Response complete', 'connected');
                    addSystemMessage('üéâ Response cycle complete!');
                    break;
                    
                case 'error':
                    addSystemMessage(`‚ùå Error: ${message.error?.message || 'Unknown error'}`);
                    updateStatus('‚ùå Error occurred', 'disconnected');
                    break;
                    
                default:
                    addSystemMessage(`‚ùì Unknown event: ${message.type}`);
            }
        }

        async function toggleRecording() {
            if (!isConnected) {
                addSystemMessage('‚ùå Please connect first');
                return;
            }
            
            if (!isRecording) {
                await startRecording();
            } else {
                await stopRecording();
            }
        }

        async function startRecording() {
            try {
                updateStatus('üîÑ Starting microphone...', 'connecting');
                
                recordingStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 24000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                mediaRecorder = new MediaRecorder(recordingStream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        // Convert to base64 and send
                        const reader = new FileReader();
                        reader.onload = function() {
                            const arrayBuffer = reader.result;
                            const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
                            
                            sendMessage({
                                type: 'input_audio_buffer.append',
                                audio: base64Audio
                            });
                        };
                        reader.readAsArrayBuffer(event.data);
                    }
                };
                
                mediaRecorder.start(100); // Send data every 100ms
                isRecording = true;
                
                talkButton.textContent = 'üõë';
                talkButton.className = 'talk-button recording';
                updateStatus('üé§ Recording - speak now!', 'listening');
                addSystemMessage('üé§ Recording started - speak now!');
                
                // Auto-stop after 15 seconds
                recordingTimeout = setTimeout(() => {
                    if (isRecording) {
                        addSystemMessage('‚è∞ Auto-stopping recording (15s limit)');
                        stopRecording();
                    }
                }, 15000);
                
            } catch (error) {
                addSystemMessage(`‚ùå Microphone error: ${error.message}`);
                updateStatus('‚ùå Microphone failed', 'disconnected');
            }
        }

        async function stopRecording() {
            if (recordingTimeout) {
                clearTimeout(recordingTimeout);
                recordingTimeout = null;
            }
            
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            
            if (recordingStream) {
                recordingStream.getTracks().forEach(track => track.stop());
                recordingStream = null;
            }
            
            isRecording = false;
            talkButton.textContent = 'üé§';
            talkButton.className = 'talk-button ready';
            updateStatus('üì§ Processing audio...', 'thinking');
            addSystemMessage('üì§ Recording stopped - processing...');
            
            // Commit audio buffer
            sendMessage({
                type: 'input_audio_buffer.commit'
            });
            
            // Request response after short delay
            setTimeout(() => {
                sendMessage({
                    type: 'response.create'
                });
            }, 500);
        }

        // Keyboard shortcuts
        document.addEventListener('keydown', function(e) {
            if (e.code === 'Space' && !e.repeat) {
                e.preventDefault();
                if (isConnected) {
                    toggleRecording();
                }
            }
        });

        // Initialize on page load
        document.addEventListener('DOMContentLoaded', function() {
            addSystemMessage('üéâ Voice Agent Interface Loaded');
            addSystemMessage('üí° Tip: You can use SPACEBAR to toggle recording');
        });
    </script>
</body>
</html>